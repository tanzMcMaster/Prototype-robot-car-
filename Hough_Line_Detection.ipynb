{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import time\n",
    "from pynq.lib.video import *\n",
    "from pynq.overlays.base import BaseOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formate output frame for HDMI output ##\n",
    "\n",
    "def format_frame(hdmi_out, frame):\n",
    "    \n",
    "    # Read input frame size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "    #print(frame.shape)\n",
    "    \n",
    "    # Creat new video formate frame\n",
    "    outframe = hdmi_out.newframe()\n",
    "    \n",
    "    # Fill new frame with zero\n",
    "    zero_img = np.zeros((480, 640), dtype=np.uint8)\n",
    "    outframe[0:480,0:640] = zero_img[0:480,0:640]\n",
    "\n",
    "    # Transfer array to the video frame\n",
    "    # For Gray imge\n",
    "    outframe[0:img_h,0:img_w] = frame[0:img_h,0:img_w]\n",
    "    # For RBG image\n",
    "    #outframe[0:480,0:640,:] = edges[0:480,0:640,:]\n",
    "    \n",
    "    return outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Line Detection ##\n",
    "\n",
    "def line_detection(roi_rate, frame):\n",
    "    \n",
    "    # Read input img size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "    \n",
    "    # Take lower part of the frame\n",
    "    roi = frame[int(img_h*roi_rate):, :]\n",
    "    \n",
    "    # Canny detect edges\n",
    "    edges = cv2.Canny(roi, 39, 130)\n",
    "\n",
    "    # Hough Line detect lines, output lines (x1, y1, x2, y2)\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges,\n",
    "        rho=1.0, # The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "        theta=np.pi/180, # The resolution of the parameter Î¸ in radians. We use 1 degree (CV_PI/180)\n",
    "        threshold=8, # The minimum number of intersections to \"*detect*\" a line\n",
    "        minLineLength=10, # The minimum number of points that can form a line. Lines with less than this number of points are disregarded.\n",
    "        maxLineGap=9 # The maximum gap between two points to be considered in the same line.\n",
    "    )\n",
    "    \n",
    "    # If no line detected\n",
    "    if lines is None:\n",
    "        # Return resized image\n",
    "        overlay = frame\n",
    "        \n",
    "    # If line detected\n",
    "    else:\n",
    "        # draw lines\n",
    "        line_img = np.zeros((img_h, img_w, 1), dtype=np.uint8)\n",
    "        \n",
    "        # center line\n",
    "        cv2.line(line_img, (int(img_w/2), 0), (int(img_w/2), img_h), 100, 1)\n",
    "\n",
    "        #for line in lines:\n",
    "            #for x1, y1, x2, y2 in line:\n",
    "                # Exclude lines that have a angle with the horizontal line less than 30 degree\n",
    "                #if (abs(y2-y1) > 0.58 * abs(x2-x1)):\n",
    "                    #cv2.line(line_img, (x1, y1+int(img_h*roi_rate)), (x2, y2+int(img_h*roi_rate)), 233, 1)\n",
    "                    #cv2.circle(line_img, (x1, y1+int(img_h*roi_rate)), 3, 233, 0)\n",
    "                    #cv2.circle(line_img, (x2, y2+int(img_h*roi_rate)), 3, 233, -1)\n",
    "                    \n",
    "        overlay = cv2.addWeighted(frame, 1, line_img, 1.0, 0.0)\n",
    "\n",
    "    return lines, overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find position offset from middle of two lines ##\n",
    "\n",
    "def offset_from_middle(roi_rate, lines, overlay):\n",
    "\n",
    "    if lines is None:\n",
    "        return 144, overlay\n",
    "    \n",
    "    else:\n",
    "        # Read input img size\n",
    "        img_h = overlay.shape[0]\n",
    "        img_w = overlay.shape[1]\n",
    "        \n",
    "        # Find the two lines that farthest to the middle \n",
    "        line_count = -1\n",
    "        left_line_num = -1\n",
    "        right_line_num = -1\n",
    "        \n",
    "        left_line_x1 = img_w/2\n",
    "        right_line_x2 = img_w/2\n",
    "\n",
    "        for line in lines:\n",
    "            line_count = line_count + 1\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                \n",
    "                # Exclude lines that are less than 30 degree to the horizontal\n",
    "                # tan(30) = 0.58\n",
    "                if (abs(y2-y1) > 0.58 * abs(x2-x1)):\n",
    "                    \n",
    "                    # Find left line\n",
    "                    if (x1 < img_w/2 and x1 < left_line_x1):\n",
    "                        left_line_x1 = x1\n",
    "                        left_line_num = line_count\n",
    "\n",
    "                    # Find right line\n",
    "                    if (x2 > img_w/2 and x2 > right_line_x2):\n",
    "                        right_line_x2 = x2\n",
    "                        right_line_num = line_count\n",
    "                        \n",
    "        # Output HDMI for Debug\n",
    "        dot_img = np.zeros((img_h, img_w, 1), dtype=np.uint8)\n",
    "        \n",
    "        for x1, y1, x2, y2 in lines[left_line_num]:\n",
    "            #y=kx+b\n",
    "            left_b = x1\n",
    "\n",
    "            #draw line\n",
    "            cv2.line(dot_img, (x1, y1+int(img_h*roi_rate)), (x2, y2+int(img_h*roi_rate)), 233, 1)\n",
    "\n",
    "            #draw dot\n",
    "            cv2.circle(dot_img, (x1, y1+int(img_h*roi_rate)), 3, 233, 0)\n",
    "            cv2.circle(dot_img, (x2, y2+int(img_h*roi_rate)), 3, 233, -1)\n",
    "\n",
    "\n",
    "        for x1, y1, x2, y2 in lines[right_line_num]:\n",
    "            #y=kx+b\n",
    "            right_b = x2\n",
    "            \n",
    "            #draw line\n",
    "            cv2.line(dot_img, (x1, y1+int(img_h*roi_rate)), (x2, y2+int(img_h*roi_rate)), 233, 1)\n",
    "            \n",
    "            #draw dot\n",
    "            cv2.circle(dot_img, (x1, y1+int(img_h*roi_rate)), 3, 233, 0)\n",
    "            cv2.circle(dot_img, (x2, y2+int(img_h*roi_rate)), 3, 233, -1)\n",
    "\n",
    "        \n",
    "        mid_dot = int((left_b + right_b)/2)\n",
    "        cv2.circle(dot_img, (mid_dot, img_h), 3, 233, -1)\n",
    "        \n",
    "        overlay = cv2.addWeighted(overlay, 0.8, dot_img, 1.0, 0.0)\n",
    "        \n",
    "        return mid_dot, overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize HDMI I/O ##\n",
    "\n",
    "# Load the overlay\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out\n",
    "\n",
    "# Configure HDMI input to gray scale ( (0.3 * R) + (0.59 * G) + (0.11 * B) )\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_in.start()\n",
    "\n",
    "# Configure Output resolution (w, h, bit per pixek)\n",
    "hdmi_out_mode = VideoMode(640,480,8)\n",
    "hdmi_out.configure(hdmi_out_mode, PIXEL_GRAY)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read camera calibration parameter ##\n",
    "\n",
    "fname = \"calibration_parameter.yaml\"\n",
    "with open(fname) as file:\n",
    "    data = yaml.load(file,Loader=yaml.Loader)\n",
    "    \n",
    "mtx = np.array([ [ data[0] , 0, data[1] ] , [ 0, data[2], data[3] ] , [0, 0, 1] ])\n",
    "dist = np.array([ [ data[4], data[5], data[6], data[7], data[8] ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main ##\n",
    "\n",
    "while(True):\n",
    "    # Read frame from HDMI input\n",
    "    frame = hdmi_in.readframe()\n",
    "    \n",
    "    # Resize frame (half of the 720p input)\n",
    "    img = cv2.resize(frame, (640,360))\n",
    "    \n",
    "    # Undistort input frame\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    \n",
    "    # Crop the frame baseo on undistortion\n",
    "    x,y,w,h = roi\n",
    "    #dst = dst[y:y+h, x:x+w]\n",
    "    \n",
    "    # Crop the frame to align center of the frame\n",
    "    dst = dst[y:y+h, x+120:x+w-150]\n",
    "\n",
    "    # ROI for line dection, the lower 1/4 of the frame\n",
    "    roi_rate = 3/4\n",
    "\n",
    "    # Dection line\n",
    "    lines, lines_overlay = line_detection(roi_rate, dst)\n",
    "    \n",
    "    # Find lines offset to the middle of the frame\n",
    "    mid_dot, offset_overlay = offset_from_middle(roi_rate, lines, lines_overlay)\n",
    "    \n",
    "    outframe = format_frame(hdmi_out, offset_overlay)\n",
    "    \n",
    "    hdmi_out.writeframe(outframe)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.stop()\n",
    "hdmi_in.stop()\n",
    "del hdmi_in, hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
