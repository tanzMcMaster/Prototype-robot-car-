{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import time\n",
    "from pynq.lib.video import *\n",
    "from pynq.lib import Pmod_PWM\n",
    "from pynq.lib.arduino import Arduino_IO\n",
    "from pynq.overlays.base import BaseOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Line detection ##\n",
    "\n",
    "def line_detection(roi_rate, frame):\n",
    "    \n",
    "    # Read input img size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "    \n",
    "    # Take lower part of the frame\n",
    "    roi = frame[int(img_h*roi_rate):, :]\n",
    "    \n",
    "    # Canny detect edges\n",
    "    edges = cv2.Canny(roi, 39, 130)\n",
    "\n",
    "    # Hough Line detect lines, output lines (x1, y1, x2, y2)\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges,\n",
    "        rho=1.0, # The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "        theta=np.pi/180, # The resolution of the parameter Î¸ in radians. We use 1 degree (CV_PI/180)\n",
    "        threshold=8, # The minimum number of intersections to \"*detect*\" a line\n",
    "        minLineLength=10, # The minimum number of points that can form a line. Lines with less than this number of points are disregarded.\n",
    "        maxLineGap=9 # The maximum gap between two points to be considered in the same line.\n",
    "    )\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find position offset from middle of two lines ##\n",
    "\n",
    "def offset_from_middle(roi_rate, lines, overlay):\n",
    "\n",
    "    if lines is None:\n",
    "        return 144, overlay\n",
    "    \n",
    "    else:\n",
    "        # Read input img size\n",
    "        img_h = overlay.shape[0]\n",
    "        img_w = overlay.shape[1]\n",
    "        \n",
    "        # Find the two lines that farthest from the middle \n",
    "        line_count = -1\n",
    "        left_line_num = -1\n",
    "        right_line_num = -1\n",
    "        \n",
    "        left_line_x1 = img_w/2\n",
    "        right_line_x2 = img_w/2\n",
    "\n",
    "        for line in lines:\n",
    "            line_count = line_count + 1\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                \n",
    "                # Exclude lines that are less than 30 degree to the horizontal\n",
    "                # tan(30) = 0.58\n",
    "                if (abs(y2-y1) > 0.58 * abs(x2-x1)):\n",
    "                    \n",
    "                    # Find left line\n",
    "                    if (x1 < img_w/2 and x1 < left_line_x1):\n",
    "                        left_line_x1 = x1\n",
    "                        left_line_num = line_count\n",
    "\n",
    "                    # Find right line\n",
    "                    if (x2 > img_w/2 and x2 > right_line_x2):\n",
    "                        right_line_x2 = x2\n",
    "                        right_line_num = line_count\n",
    "                        \n",
    "        # Create new empty frame for drawing\n",
    "        dot_img = np.zeros((img_h, img_w, 1), dtype=np.uint8)\n",
    "        \n",
    "        # Draw frame center line\n",
    "        cv2.line(dot_img, (int(img_w/2), 0), (int(img_w/2), img_h), 100, 1)\n",
    "        \n",
    "        # Draw left line\n",
    "        for x1, y1, x2, y2 in lines[left_line_num]:\n",
    "            #y=kx+b\n",
    "            left_b = x1\n",
    "            #draw dot\n",
    "            cv2.circle(dot_img, (x1, y1+int(img_h*roi_rate)), 3, 233, 0)\n",
    "            cv2.circle(dot_img, (x2, y2+int(img_h*roi_rate)), 3, 233, -1)\n",
    "            #draw line\n",
    "            cv2.line(dot_img, (x1, y1+int(img_h*roi_rate)), (x2, y2+int(img_h*roi_rate)), 233, 1)\n",
    "\n",
    "        # Draw right line\n",
    "        for x1, y1, x2, y2 in lines[right_line_num]:\n",
    "            #y=kx+b\n",
    "            right_b = x2\n",
    "            #draw dot\n",
    "            cv2.circle(dot_img, (x1, y1+int(img_h*roi_rate)), 3, 233, 0)\n",
    "            cv2.circle(dot_img, (x2, y2+int(img_h*roi_rate)), 3, 233, -1)\n",
    "            #draw line\n",
    "            cv2.line(dot_img, (x1, y1+int(img_h*roi_rate)), (x2, y2+int(img_h*roi_rate)), 233, 1)\n",
    "\n",
    "        # Draw middle point of two lines\n",
    "        mid_dot = int((left_b + right_b)/2)\n",
    "        cv2.circle(dot_img, (mid_dot, img_h), 3, 233, -1)\n",
    "        \n",
    "        # Combine drawings with input frame\n",
    "        overlay = cv2.addWeighted(overlay, 1.0, dot_img, 1.0, 0.0)\n",
    "        \n",
    "        return mid_dot, overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Car detection ##\n",
    "\n",
    "def car_detection(frame):\n",
    "\n",
    "    # Read input img size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "   \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(frame)\n",
    "    \n",
    "    # draw lines\n",
    "    zero_img = np.zeros((img_h, img_w, 1), dtype=np.uint8)\n",
    "\n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (233), 1)\n",
    "    \n",
    "    #overlay = cv2.addWeighted(frame, 1, zero_img, 1.0, 0.0)\n",
    "    \n",
    "    return cars ,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format frame for HDMI output ##\n",
    "\n",
    "def format_frame(hdmi_out, frame):\n",
    "    \n",
    "    # Read input frame size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "    \n",
    "    # Create new video frame\n",
    "    outframe = hdmi_out.newframe()\n",
    "    \n",
    "    # Fill new video frame with zero\n",
    "    zero_img = np.zeros((480, 640), dtype=np.uint8)\n",
    "    outframe[0:480,0:640] = zero_img[0:480,0:640]\n",
    "\n",
    "    # Transfer input frame to the video frame\n",
    "    # For Gray imge\n",
    "    outframe[0:img_h,0:img_w] = frame[0:img_h,0:img_w]\n",
    "    \n",
    "    return outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Robot stop ##\n",
    "\n",
    "def robot_stop():\n",
    "    enable_L.stop()\n",
    "    forward_L.write(0)\n",
    "    backward_L.write(0)\n",
    "\n",
    "    enable_R.stop()\n",
    "    forward_R.write(0)\n",
    "    backward_R.write(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Robot perportional control ##\n",
    "\n",
    "def robot_run(left_percent, right_percent):\n",
    "    \n",
    "    left_duty = int(53 + (25) * left_percent - (30) * right_percent)\n",
    "    right_duty = int(53 + (25) * right_percent - (30) * left_percent)\n",
    "\n",
    "    \n",
    "    enable_L.generate(10,left_duty)\n",
    "    forward_L.write(1)\n",
    "    backward_L.write(0)\n",
    "\n",
    "    enable_R.generate(10,right_duty)\n",
    "    forward_R.write(1)\n",
    "    backward_R.write(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize HDMI I/O ##\n",
    "\n",
    "# Load the overlay\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out\n",
    "\n",
    "# Configure HDMI input to gray scale ( (0.3 * R) + (0.59 * G) + (0.11 * B) )\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_in.start()\n",
    "\n",
    "# Configure Output resolution (w, h, bit per pixek)\n",
    "hdmi_out_mode = VideoMode(640,480,8)\n",
    "hdmi_out.configure(hdmi_out_mode, PIXEL_GRAY)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read camera calibration parameter ##\n",
    "\n",
    "fname = \"calibration_parameter.yaml\"\n",
    "with open(fname) as file:\n",
    "    data = yaml.load(file,Loader=yaml.Loader)\n",
    "    \n",
    "mtx = np.array([ [ data[0] , 0, data[1] ] , [ 0, data[2], data[3] ] , [0, 0, 1] ])\n",
    "dist = np.array([ [ data[4], data[5], data[6], data[7], data[8] ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize on borad LED and switch ##\n",
    "\n",
    "led1 = base.leds[1] #Corresponds to LED LD1\n",
    "led2 = base.leds[2] #Corresponds to LED LD2\n",
    "led4 = base.rgbleds[4] #Corresponds to LED LD3\n",
    "led5 = base.rgbleds[5] #Corresponds to LED LD4\n",
    "\n",
    "sw0 = base.switches[0] #Corresponds to SW0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Arduino pins for motor control ##\n",
    "\n",
    "enable_L  = Pmod_PWM(base.PMODA,1)\n",
    "forward_L = Arduino_IO(base.ARDUINO, 7, 'out')\n",
    "backward_L = Arduino_IO(base.ARDUINO, 8, 'out')\n",
    "\n",
    "enable_R = Pmod_PWM(base.PMODB,1)\n",
    "forward_R = Arduino_IO(base.ARDUINO, 11, 'out')\n",
    "backward_R = Arduino_IO(base.ARDUINO, 9, 'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main ##\n",
    "\n",
    "# ROI for line dection set to the lower 1/4 of the frame\n",
    "roi_rate = 3/4\n",
    "\n",
    "# Load car harr classifier\n",
    "car_classifier = cv2.CascadeClassifier('haar_toy_car.xml')\n",
    "\n",
    "while(True):\n",
    "    # Read frame from HDMI input\n",
    "    frame = hdmi_in.readframe()\n",
    "    \n",
    "    # Resize frame (half of the 720p input)\n",
    "    img = cv2.resize(frame, (640,360))\n",
    "    \n",
    "    # Undistort input frame\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    \n",
    "    # Crop the frame based on undistortion roi\n",
    "    x,y,w,h = roi\n",
    "    #dst = dst[y:y+h, x:x+w]\n",
    "    \n",
    "    # Crop the frame to align visual center of the frame\n",
    "    dst = dst[y:y+h, x+120:x+w-150]\n",
    "\n",
    "    # Detect car\n",
    "    cars, cars_overlay = car_detection(dst)\n",
    "    \n",
    "    # Stop the robot when car detected, show status with LED\n",
    "    if(len(cars) > 0):\n",
    "        robot_stop()\n",
    "        led5.on(4)\n",
    "        \n",
    "    if(len(cars) == 0):\n",
    "        led5.on(3)\n",
    "    \n",
    "    # Detect line\n",
    "    lines = line_detection(roi_rate, dst)\n",
    "    \n",
    "    # Find lines offset to the middle of the frame\n",
    "    mid_dot, offset_overlay = offset_from_middle(roi_rate, lines, dst)\n",
    "    \n",
    "    # Follow the lines with perportional control\n",
    "    mid_line = offset_overlay.shape[1]/2\n",
    "    \n",
    "    right_percent = 0\n",
    "    left_percent = 0\n",
    "    \n",
    "    if(mid_dot < mid_line):\n",
    "        right_percent = abs(mid_dot - mid_line)/69\n",
    "        if (right_percent >= 1):\n",
    "            right_percent = 1\n",
    "        led1.on()\n",
    "        led2.off()\n",
    "        #print(\"right\", mid_line)\n",
    "        \n",
    "    if(mid_dot > mid_line):\n",
    "        left_percent = abs(mid_dot - mid_line)/69\n",
    "        if (left_percent >= 1):\n",
    "            left_percent = 1\n",
    "        led2.on()\n",
    "        led1.off()\n",
    "        #print(\"left\", mid_line)\n",
    "    \n",
    "    # Real Switch on/off to generate PWM signal\n",
    "    if ((sw0.read() == True) and (len(cars) == 0)):\n",
    "        led4.write(3)\n",
    "        robot_run(left_percent, right_percent)\n",
    "        \n",
    "    if (sw0.read() == False):\n",
    "        led4.write(4)\n",
    "        robot_stop()\n",
    "    \n",
    "    # Conbine vehicle and line dection output frame\n",
    "    overlay = cv2.addWeighted(offset_overlay, 0.5, cars_overlay, 0.5, 0.0)\n",
    "\n",
    "    # Output to HDMI\n",
    "    outframe = format_frame(hdmi_out, overlay)\n",
    "    hdmi_out.writeframe(outframe)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "led1.off()\n",
    "led2.off()\n",
    "led4.off()\n",
    "led5.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.stop()\n",
    "hdmi_in.stop()\n",
    "del hdmi_in, hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
