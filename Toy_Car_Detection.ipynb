{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import time\n",
    "from pynq.lib.video import *\n",
    "from pynq.overlays.base import BaseOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detection car ##\n",
    "\n",
    "def car_detection(frame):\n",
    "\n",
    "    # Read input img size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "   \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(frame)\n",
    "    \n",
    "    # draw lines\n",
    "    zero_img = np.zeros((img_h, img_w, 1), dtype=np.uint8)\n",
    "\n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (233), 1)\n",
    "    \n",
    "    #overlay = cv2.addWeighted(frame, 1, zero_img, 1.0, 0.0)\n",
    "    \n",
    "    return cars ,frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formate output frame for HDMI output ##\n",
    "\n",
    "def video_HDMI(hdmi_out, frame):\n",
    "    \n",
    "    # Read input frame size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "    #print(frame.shape)\n",
    "    \n",
    "    # Creat new video formate frame\n",
    "    outframe = hdmi_out.newframe()\n",
    "    \n",
    "    # Fill new frame with zero\n",
    "    zero_img = np.zeros((480, 640), dtype=np.uint8)\n",
    "    outframe[0:480,0:640] = zero_img[0:480,0:640]\n",
    "\n",
    "    # Transfer array to the video frame\n",
    "    # For Gray imge\n",
    "    outframe[0:img_h,0:img_w] = frame[0:img_h,0:img_w]\n",
    "    # For RBG image\n",
    "    #outframe[0:480,0:640,:] = edges[0:480,0:640,:]\n",
    "    \n",
    "    return outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize HDMI I/O ##\n",
    "\n",
    "# Load the overlay\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out\n",
    "\n",
    "# Configure HDMI input to gray scale ( (0.3 * R) + (0.59 * G) + (0.11 * B) )\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_in.start()\n",
    "\n",
    "# Configure Output resolution (w, h, bit per pixek)\n",
    "hdmi_out_mode = VideoMode(640,480,8)\n",
    "hdmi_out.configure(hdmi_out_mode, PIXEL_GRAY)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read camera calibration parameter ##\n",
    "\n",
    "fname = \"calibration_parameter.yaml\"\n",
    "with open(fname) as file:\n",
    "    data = yaml.load(file,Loader=yaml.Loader)\n",
    "    \n",
    "mtx = np.array([ [ data[0] , 0, data[1] ] , [ 0, data[2], data[3] ] , [0, 0, 1] ])\n",
    "dist = np.array([ [ data[4], data[5], data[6], data[7], data[8] ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load car harr classifier\n",
    "car_classifier = cv2.CascadeClassifier('haar_toycar.xml')\n",
    "\n",
    "while(True):\n",
    "    # Read frame from HDMI input\n",
    "    frame = hdmi_in.readframe()\n",
    "    \n",
    "    # Resize frame (half of the 720p input)\n",
    "    img = cv2.resize(frame, (640,360))\n",
    "    \n",
    "    # Undistort input frame\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    \n",
    "    # Crop the frame baseo on undistortion\n",
    "    x,y,w,h = roi\n",
    "    #dst = dst[y:y+h, x:x+w]\n",
    "    \n",
    "    # Crop the frame to align center of the frame\n",
    "    dst = dst[y:y+h, x+120:x+w-150]\n",
    "\n",
    "    # Detect car\n",
    "    cars, cars_overlay = car_detection(dst)\n",
    "    \n",
    "    # Output frame\n",
    "    outframe = video_HDMI(hdmi_out, cars_overlay)\n",
    "    \n",
    "    hdmi_out.writeframe(outframe)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
