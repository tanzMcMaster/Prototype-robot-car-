{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import yaml\n",
    "import PIL.Image\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put numpy array to video formate frame\n",
    "def video_HDMI(hdmi_out, frame):\n",
    "    \n",
    "    # Read input frame size\n",
    "    img_h = frame.shape[0]\n",
    "    img_w = frame.shape[1]\n",
    "    #print(frame.shape)\n",
    "    \n",
    "    # Creat new video formate frame\n",
    "    outframe = hdmi_out.newframe()\n",
    "    \n",
    "    # Fill new frame with zero\n",
    "    zero_img = np.zeros((480, 640), dtype=np.uint8)\n",
    "    outframe[0:480,0:640] = zero_img[0:480,0:640]\n",
    "\n",
    "    # Transfer array to the video frame\n",
    "    # For Gray imge\n",
    "    outframe[0:img_h,0:img_w] = frame[0:img_h,0:img_w]\n",
    "    # For RBG image\n",
    "    #outframe[0:480,0:640,:] = edges[0:480,0:640,:]\n",
    "    \n",
    "    return outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HDMI I/O\n",
    "\n",
    "# Load the overlay\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out\n",
    "\n",
    "# Configure HDMI input to gray scale ( (0.3 * R) + (0.59 * G) + (0.11 * B) )\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_in.start()\n",
    "\n",
    "# Configure Output resolution (w, h, bit per pixek)\n",
    "hdmi_out_mode = VideoMode(640,480,8)\n",
    "hdmi_out.configure(hdmi_out_mode, PIXEL_GRAY)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read calibration parameter\n",
    "\n",
    "fname = \"calibration_parameter.yaml\"\n",
    "with open(fname) as file:\n",
    "    data = yaml.load(file,Loader=yaml.Loader)\n",
    "    \n",
    "mtx = np.array([ [ data[0] , 0, data[1] ] , [ 0, data[2], data[3] ] , [0, 0, 1] ])\n",
    "dist = np.array([ [ data[4], data[5], data[6], data[7], data[8] ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_saved = 0 # Track number of images saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display live video to ensure the subject is within the view\n",
    "# Stop this block once you confirm you have the desired view\n",
    "# Run the next block to take picture\n",
    "while (True):\n",
    "    \n",
    "    gray = hdmi_in.readframe()\n",
    "    \n",
    "    img = cv2.resize(gray, (640,360))\n",
    "\n",
    "    # Undistort\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    \n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    \n",
    "    # crop the image\n",
    "    x,y,w,h = roi\n",
    "    \n",
    "    # Align center mannually\n",
    "    dst = dst[y:y+h, x+120:x+w-150]\n",
    "    #print(-20+w-150)\n",
    "    \n",
    "    outframe = video_HDMI(hdmi_out, dst)\n",
    "    \n",
    "    hdmi_out.writeframe(outframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code will save one image at a time\n",
    "# Get image with different angle and distant for the subject\n",
    "# The image will be stored under the image_path\n",
    "\n",
    "cwd = os.getcwd() # get current working direction\n",
    "\n",
    "### parameter ###\n",
    "image_path = cwd + '/new_pic/' # path to store new user's image\n",
    "\n",
    "gray = hdmi_in.readframe()\n",
    "\n",
    "img = cv2.resize(gray, (640,360))\n",
    "\n",
    "# Undistort\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "\n",
    "# Align center mannually\n",
    "dst = dst[y:y+h, x+120:x+w-150]\n",
    "#print(-20+w-150)\n",
    "\n",
    "\n",
    "cv2.imwrite(image_path + str(image_saved) + \".bmp\", dst) # save image\n",
    "\n",
    "image_saved = image_saved + 1 # save image counting\n",
    "\n",
    "print(image_saved)\n",
    "\n",
    "outframe = video_HDMI(hdmi_out, dst)\n",
    "\n",
    "hdmi_out.writeframe(outframe)\n",
    "\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After taking all picture, stop HMDI ports\n",
    "\n",
    "hdmi_out.stop()\n",
    "hdmi_in.stop()\n",
    "del hdmi_in, hdmi_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
